import { NextRequest, NextResponse } from 'next/server'
import { openai } from '@/lib/openai'
import { getServerSupabase } from '@/lib/supabase-server'
import { ApiResponse, Evaluation } from '@/lib/types'

export async function POST(request: NextRequest) {
  // âœ… 1. Ã–NCE KEY VAR MI BAK
  const openaiKey = process.env.OPENAI_API_KEY

  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
  console.log('ðŸ”‘ OPENAI KEY CHECK: ')
  console.log('  - Exists:', !!openaiKey)
  console.log('  - Length:', openaiKey?. length || 0)
  console.log('  - Starts with sk-:', openaiKey?.startsWith('sk-'))
  console.log('  - First 25 chars:', openaiKey?.substring(0, 25))
  console.log('  - Will use MOCK?', ! openaiKey)
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')

  let questionId = ''
  let question = ''
  let answer = ''
  let interviewId = ''

  try {
    const body = await request.json()
    questionId = body.questionId
    question = body.question
    answer = body.answer
    interviewId = body.interviewId
  } catch (parseError) {
    console.error('âŒ Request body parse error:', parseError)
    return NextResponse.json(
      { success: false, error: 'Invalid request body' } as ApiResponse,
      { status: 400 }
    )
  }

  try {
    console.log('ðŸ§  Evaluating answer for question:', questionId)

    if (!question || !answer) {
      return NextResponse.json(
        { success: false, error: 'Question and answer are required' } as ApiResponse,
        { status: 400 }
      )
    }

    const useMock = !process.env. OPENAI_API_KEY

    let evaluationResult:  {
      score: number
      feedback: string
      strengths: string[]
      improvements: string[]
    }

    if (useMock) {
      console.log('âš ï¸ Using mock evaluation (NO OPENAI KEY)')

      // âœ… SIKI MOCK PUANLAMA
      const answerTrimmed = answer.trim()
      const answerLength = answerTrimmed.length
      const wordCount = answerTrimmed.split(/\s+/).filter((w) => w.length > 0).length

      const meaningfulWords = answerTrimmed
        .split(/\s+/)
        .filter((w) => /[a-zA-ZÄŸÃ¼ÅŸÄ±Ã¶Ã§ÄžÃœÅžÄ°Ã–Ã‡]{2,}/.test(w))
      const meaningfulWordCount = meaningfulWords.length

      console.log(`ðŸ“Š Answer analysis:`, {
        length: answerLength,
        words: wordCount,
        meaningfulWords: meaningfulWordCount,
        preview: answerTrimmed.substring(0, 50),
      })

      let score = 1

      if (answerLength < 10 || meaningfulWordCount < 3) {
        score = 1
      } else if (answerLength < 30 || meaningfulWordCount < 8) {
        score = 2
      } else if (answerLength < 60 || meaningfulWordCount < 15) {
        score = 3
      } else if (answerLength < 100 || meaningfulWordCount < 25) {
        score = 5
      } else if (answerLength < 200 || meaningfulWordCount < 40) {
        score = 7
      } else if (answerLength < 350 || meaningfulWordCount < 60) {
        score = 8
      } else {
        score = 9
      }

      const variation = Math.random() > 0.5 ? 0 : Math.random() > 0.5 ? 1 : -1
      score = Math.max(1, Math.min(10, score + variation))

      console.log(`ðŸ“Š Final mock score: ${score}/10`)

      evaluationResult = {
        score,
        feedback: 
          score >= 8
            ? 'MÃ¼kemmel bir cevap!  Konuya hakimiyetiniz ve detaylÄ± aÃ§Ä±klamalarÄ±nÄ±z Ã§ok iyi.'
            : score >= 6
            ? 'CevabÄ±nÄ±z genel olarak iyiydi.  Daha spesifik Ã¶rnekler vererek gÃ¼Ã§lendirebilirsiniz.'
            :  score >= 4
            ? 'Soruyu anladÄ±nÄ±z fakat daha detaylÄ± ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir cevap verebilirdiniz.'
            : score >= 2
            ? 'CevabÄ±nÄ±z Ã§ok kÄ±sa ve yÃ¼zeysel kaldÄ±. LÃ¼tfen daha detaylÄ± ve Ã¶rneklerle desteklenmiÅŸ cevaplar verin.'
            : 'CevabÄ±nÄ±z yetersiz. Soruyu ciddiye alÄ±p detaylÄ±, yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir cevap vermeniz bekleniyor.',
        strengths: 
          score >= 7
            ? [
                'Konuya hakim olduÄŸunuz anlaÅŸÄ±lÄ±yor',
                'DetaylÄ± ve net aÃ§Ä±klama yaptÄ±nÄ±z',
                'Ä°yi yapÄ±landÄ±rÄ±lmÄ±ÅŸ cevap',
              ]
            : score >= 5
            ? ['Soruyu doÄŸru anladÄ±nÄ±z', 'Temel bilgileri verdiniz']
            : score >= 3
            ? ['Soruya cevap vermeye Ã§alÄ±ÅŸtÄ±nÄ±z']
            : ['Temel dÃ¼zeyde yanÄ±t verdiniz'],
        improvements: 
          score >= 7
            ? [
                'Daha fazla gerÃ§ek dÃ¼nya Ã¶rneÄŸi ekleyebilirsiniz',
                'Teknik derinliÄŸi artÄ±rabilirsiniz',
              ]
            : score >= 5
            ? ['Daha fazla detay ekleyin', 'GerÃ§ek Ã¶rneklerle destekleyin', 'CevabÄ±nÄ±zÄ± geniÅŸletin']
            : score >= 3
            ? [
                'Ã‡ok daha detaylÄ± cevap verin',
                'Ã–rneklerle destekleyin',
                'CevabÄ±nÄ±zÄ± yapÄ±landÄ±rÄ±n',
                'En az 100-150 kelime yazÄ±n',
              ]
            :  [
                'Soruyu ciddiye alÄ±n',
                'DetaylÄ±, anlamlÄ± cevaplar verin',
                'En az 100-150 kelime kullanÄ±n',
                'Deneyimlerinizden Ã¶rnekler paylaÅŸÄ±n',
              ],
      }
    } else {
      console.log('ðŸ“¡ Calling OpenAI API for evaluation...')

      const completion = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages:  [
          {
            role:  'system',
            content: 
              'You are an expert interviewer.  Provide constructive feedback with a score out of 10. Be strict:  answers shorter than 50 words should get maximum 3/10. Answers with no real content (like "q", "test", random characters) should get 1/10.',
          },
          {
            role: 'user',
            content: `Evaluate this interview answer: 

Question: ${question}

Answer: ${answer}

Provide: 
1. Score (0-10) - BE STRICT, short or meaningless answers get 1-3/10
2. Detailed feedback (2-3 sentences)
3. Strengths (array of 2-3 points)
4. Areas for improvement (array of 2-3 points)

Respond in JSON format with keys: score, feedback, strengths, improvements`,
          },
        ],
        temperature: 0.7,
        max_tokens: 500,
      })

      const content = completion.choices[0].message.content || '{}'
      evaluationResult = JSON.parse(content)
      console.log('âœ… OpenAI evaluation received:', evaluationResult)
    }

    // âœ… SUPABASE'E KAYDET
    const serverSupabase = getServerSupabase()

    const { error:  updateError } = await serverSupabase
      .from('questions')
      .update({
        answer_text: answer,
        score: evaluationResult.score,
        feedback: evaluationResult.feedback,
      })
      .eq('id', questionId)

    if (updateError) {
      console.error('âŒ Question update error:', updateError)
    } else {
      console.log('âœ… Answer saved to database')
    }

    // âœ… TÃœM SORULAR CEVAPLANDI MI KONTROL ET
    if (interviewId) {
      try {
        const { data: allQuestions } = await serverSupabase
          .from('questions')
          .select('id, answer_text, score')
          .eq('interview_id', interviewId)

        if (allQuestions) {
          const allAnswered = allQuestions.every((q) => q.answer_text && q.score !== undefined)

          if (allAnswered) {
            console.log('ðŸ All questions answered, completing interview.. .')

            const totalScore = allQuestions.reduce((sum, q) => sum + (q.score || 0), 0)
            const averageScore = Math.round((totalScore / allQuestions.length) * 10)

            console.log(`ðŸ“Š Final score: ${averageScore}%`)

            const { error:  completeError } = await serverSupabase
              .from('interviews')
              .update({
                status: 'completed',
                score: averageScore,
                updated_at: new Date().toISOString(),
              })
              .eq('id', interviewId)

            if (completeError) {
              console. error('âŒ Interview completion error:', completeError)
            } else {
              console.log('âœ… Interview completed successfully!')
            }
          }
        }
      } catch (completeError) {
        console.error('âš ï¸ Interview completion check failed:', completeError)
      }
    }

    return NextResponse.json({
      success: true,
      data: {
        questionId,
        ... evaluationResult,
      },
    } as ApiResponse)
  } catch (error) {
    console.error('ðŸ’¥ Evaluation error:', error)

    const answerLength = answer.trim().length
    const meaningfulWords = answer
      .trim()
      .split(/\s+/)
      .filter((w) => /[a-zA-ZÄŸÃ¼ÅŸÄ±Ã¶Ã§ÄžÃœÅžÄ°Ã–Ã‡]{2,}/.test(w))

    let score = 1
    if (answerLength < 10 || meaningfulWords.length < 3) score = 1
    else if (answerLength < 30 || meaningfulWords.length < 8) score = 2
    else if (answerLength < 60 || meaningfulWords.length < 15) score = 3
    else if (answerLength < 100 || meaningfulWords. length < 25) score = 5
    else if (answerLength < 200 || meaningfulWords.length < 40) score = 7
    else score = 8

    return NextResponse.json({
      success: true,
      data: {
        questionId,
        score,
        feedback: 'CevabÄ±nÄ±z deÄŸerlendirildi.',
        strengths: ['Cevap verdiniz'],
        improvements: ['Daha detaylÄ± cevap verin', 'En az 100-150 kelime kullanÄ±n'],
      },
    } as ApiResponse)
  }
}
