import { NextRequest, NextResponse } from 'next/server'
import { openai } from '@/lib/openai'
import { getServerSupabase } from '@/lib/supabase-server'
import { ApiResponse, Evaluation } from '@/lib/types'

export async function POST(request: NextRequest) {
  let questionId = ''
  let question = ''
  let answer = ''
  let interviewId = ''

  try {
    const body = await request.json()
    questionId = body.questionId
    question = body.question
    answer = body.answer
    interviewId = body.interviewId // ‚Üê Ekle
  } catch (parseError) {
    console.error('‚ùå Request body parse error:', parseError)
    return NextResponse.json(
      { success: false, error: 'Invalid request body' } as ApiResponse,
      { status: 400 }
    )
  }

  try {
    console.log('üß† Evaluating answer for question:', questionId)

    if (!question || !answer) {
      return NextResponse.json(
        { success: false, error: 'Question and answer are required' } as ApiResponse,
        { status: 400 }
      )
    }

    const useMock = ! process.env.OPENAI_API_KEY

    let evaluationResult: {
      score: number
      feedback: string
      strengths: string[]
      improvements: string[]
    }

    if (useMock) {
      console.log('‚ö†Ô∏è Using mock evaluation')

      // ‚úÖ AKILLI MOCK PUANLAMA
      const answerLength = answer.trim().length
      const wordCount = answer.trim().split(/\s+/).length

      let score = 5

      if (answerLength < 20 || wordCount < 5) {
        score = 3
      } else if (wordCount < 15) {
        score = 5
      } else if (wordCount < 30) {
        score = 6
      } else if (wordCount < 50) {
        score = 7
      } else if (wordCount < 80) {
        score = 8
      } else {
        score = 9
      }

      score = Math.max(1, Math.min(10, score + Math.floor(Math.random() * 3) - 1))

      console.log(`üìä Mock score: ${score}/10 (${wordCount} words, ${answerLength} chars)`)

      evaluationResult = {
        score,
        feedback: 
          score >= 8
            ? 'M√ºkemmel bir cevap!  Konuya hakimiyetiniz ve detaylƒ± a√ßƒ±klamalarƒ±nƒ±z √ßok iyi.'
            : score >= 6
            ? 'Cevabƒ±nƒ±z genel olarak iyiydi. Daha spesifik √∂rnekler vererek g√º√ßlendirebilirsiniz.'
            :  score >= 4
            ? 'Soruyu anladƒ±nƒ±z fakat daha detaylƒ± ve yapƒ±landƒ±rƒ±lmƒ±≈ü bir cevap verebilirdiniz.'
            : 'Cevabƒ±nƒ±z √ßok kƒ±sa kaldƒ±. L√ºtfen daha detaylƒ± ve √∂rneklerle desteklenmi≈ü cevaplar verin.',
        strengths: 
          score >= 7
            ? [
                'Konuya hakim olduƒüunuz anla≈üƒ±lƒ±yor',
                'Detaylƒ± ve net a√ßƒ±klama yaptƒ±nƒ±z',
                'ƒ∞yi yapƒ±landƒ±rƒ±lmƒ±≈ü cevap',
              ]
            : score >= 5
            ? ['Soruyu doƒüru anladƒ±nƒ±z', 'Net ifade kullandƒ±nƒ±z']
            : ['Temel konuyu kavradƒ±nƒ±z'],
        improvements: 
          score >= 7
            ? ['Daha fazla ger√ßek d√ºnya √∂rneƒüi ekleyebilirsiniz']
            : score >= 5
            ? ['Daha fazla teknik detay ekleyin', 'Ger√ßek √∂rneklerle destekleyin']
            : [
                '√áok daha detaylƒ± cevap verin',
                '√ñrneklerle destekleyin',
                'Cevabƒ±nƒ±zƒ± yapƒ±landƒ±rƒ±n',
              ],
      }
    } else {
      console.log('üì° Calling OpenAI for evaluation.. .')

      const completion = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages:  [
          {
            role:  'system',
            content: 
              'You are an expert interviewer.  Provide constructive feedback with a score out of 10.',
          },
          {
            role: 'user',
            content: `Evaluate this interview answer: 

Question: ${question}

Answer: ${answer}

Provide: 
1. Score (0-10)
2. Detailed feedback (2-3 sentences)
3. Strengths (array of 2-3 points)
4. Areas for improvement (array of 2-3 points)

Respond in JSON format with keys: score, feedback, strengths, improvements`,
          },
        ],
        temperature: 0.7,
        max_tokens: 500,
      })

      const content = completion.choices[0].message.content || '{}'
      evaluationResult = JSON.parse(content)
      console.log('‚úÖ OpenAI evaluation received')
    }

    // ‚úÖ SUPABASE'E KAYDET
    const serverSupabase = getServerSupabase()

    const { error:  updateError } = await serverSupabase
      .from('questions')
      .update({
        answer_text: answer,
        score: evaluationResult.score,
        feedback: evaluationResult.feedback,
      })
      .eq('id', questionId)

    if (updateError) {
      console.error('‚ùå Question update error:', updateError)
    } else {
      console.log('‚úÖ Answer saved to database')
    }

    // ‚úÖ T√úM SORULAR CEVAPLANDI MI KONTROL ET
    if (interviewId) {
      try {
        const { data: allQuestions } = await serverSupabase
          .from('questions')
          .select('id, answer_text, score')
          .eq('interview_id', interviewId)

        if (allQuestions) {
          const allAnswered = allQuestions.every((q) => q.answer_text && q.score !== undefined)

          if (allAnswered) {
            console.log('üèÅ All questions answered, completing interview.. .')

            const totalScore = allQuestions.reduce((sum, q) => sum + (q.score || 0), 0)
            const averageScore = Math.round((totalScore / allQuestions.length) * 10)

            console.log(`üìä Final score: ${averageScore}%`)

            // Interview'i tamamla
            const { error: completeError } = await serverSupabase
              .from('interviews')
              .update({
                status: 'completed',
                score: averageScore,
                updated_at: new Date().toISOString(),
              })
              .eq('id', interviewId)

            if (completeError) {
              console. error('‚ùå Interview completion error:', completeError)
            } else {
              console.log('‚úÖ Interview completed successfully!')
            }
          }
        }
      } catch (completeError) {
        console.error('‚ö†Ô∏è Interview completion check failed:', completeError)
      }
    }

    return NextResponse.json({
      success: true,
      data: {
        questionId,
        ... evaluationResult,
      },
    } as ApiResponse)
  } catch (error) {
    console.error('üí• Evaluation error:', error)

    const answerLength = answer.trim().length
    const wordCount = answer. trim().split(/\s+/).length

    let score = 5
    if (answerLength < 20 || wordCount < 5) score = 3
    else if (wordCount < 15) score = 5
    else if (wordCount < 30) score = 6
    else if (wordCount < 50) score = 7
    else if (wordCount < 80) score = 8
    else score = 9

    score = Math.max(1, Math.min(10, score + Math.floor(Math.random() * 3) - 1))

    return NextResponse.json({
      success: true,
      data: {
        questionId,
        score,
        feedback: 'Cevabƒ±nƒ±z deƒüerlendirildi.',
        strengths: ['Soruyu anladƒ±nƒ±z'],
        improvements: ['Daha detaylƒ± cevap verin'],
      },
    } as ApiResponse)
  }
}
